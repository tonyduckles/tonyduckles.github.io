<!DOCTYPE html>
<html>
<head>
    
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>All-In-One Home File Server: VMware ESXi, OpenIndiana, and ZFS &#8211; Nynim.org</title>
    <link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com">
    <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Tony Duckles on programming, photography, and general geekery
">
    <meta name="robots" content="all">
    <meta name="author" content="Tony Duckles">
    
    <meta name="keywords" content="esxi openindiana, esxi openindiana zfs, all in one openindiana zfs, home all in one esxi">
    <link rel="canonical" href="http://nynim.org/blog/2012/06/04/all-in-one-home-file-server-vmware-esxi-openindiana-and-zfs/">
    <link rel="alternate" type="application/atom" title="Nynim.org" href="/atom.xml" />
    <link href="/favicon.png" rel="icon">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201708182152" type="text/css">
    <link href='/stylesheets/all-958d45fee415f2d267d37b7939d5bff3.css' media='all' rel='stylesheet' type='text/css'>

    <!-- Fonts -->
    
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- MathJax -->
    

    <!-- Verifications -->
    
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="All-In-One Home File Server: VMware ESXi, OpenIndiana, and ZFS">
    <meta property="og:description" content="Using VMware ESXi for a home file-server along with ZFS-powered mass storage.">
    <meta property="og:url" content="http://nynim.org/blog/2012/06/04/all-in-one-home-file-server-vmware-esxi-openindiana-and-zfs/">
    <meta property="og:site_name" content="Nynim.org">
    

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@tonyduckles" />
        <meta name="twitter:creator" content="@tonyduckles" />
    
    <meta name="twitter:title" content="All-In-One Home File Server: VMware ESXi, OpenIndiana, and ZFS" />
    <meta name="twitter:description" content="Tony Duckles on programming, photography, and general geekery
" />
    <meta name="twitter:url" content="http://nynim.org/blog/2012/06/04/all-in-one-home-file-server-vmware-esxi-openindiana-and-zfs/" />
    

    
    <script type="text/javascript">
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
       (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
       })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       ga('create', 'UA-6748678-1', 'auto');
       ga('send', 'pageview');
    </script>
    
</head>
<body class="site">
  
	

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="http://nynim.org" class="site-title">nynim.org</a>
      <nav class="site-nav">
        <a href="/blog/">Blog</a>
    

    

    
    
    
    
        <a href="/blog/archives/">Archives</a>
    

    

    
    
    
    
        <a href="/code/">Code</a>
    

    

    
    
    
    
        <a href="/guitar-tabs/">Guitar Tabs</a>
    

    

    
    
    
    
        <a href="/about/">About</a>
      </nav>
      <div class="clearfix"></div>
      
        <div class="social-icons">
  <div class="social-icons-right">
    
      <a class="fa fa-github" href="https://github.com/tonyduckles"></a>
    
    
    
    
    
      <a class="fa fa-twitter" href="https://twitter.com/tonyduckles"></a>
    
    
    
    
    
      <a class="fa fa-linkedin" href="https://www.linkedin.com/in/tonyduckles"></a>
    
    
    
    
    
    
      <a class="fa fa-instagram" href="https://www.instagram.com/tonyduckles"></a>
    
    
      <a class="fa fa-flickr" href="https://www.flickr.com/photos/tonyduckles"></a>
    
    
      <a class="fa fa-lastfm" href="https://last.fm/user/tonyduckles"></a>
    
    
      <a class="fa fa-thumb-tack" href="https://pinboard.in/u:tduckles"></a>
    
    <a class="fa fa-rss" href="/atom.xml"></a>
    <a class="fa fa-envelope" href="mailto:tony@nynim.org"></a>
  </div>
  <div class="right">
    
    
    
  </div>
</div>
<div class="clearfix"></div>
      
    </div>
  </div>
</header>

    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        



<div class="post-header mb2">
  <h1>
  
    All-In-One Home File Server: VMware ESXi, OpenIndiana, and ZFS
  
  </h1>
  <span class="post-meta">Jun 4, 2012</span><br>
  
  <span class="post-meta small">
  
    5 minute read
  
  </span>
</div>

<article class="post-content">
  <p>Just over a year ago, I built a new home file-server since I was quickly
outgrowing my existing storage capacity. Rather than just dropping more HDD's
into the existing hardware I had running, I succumbed to geek techno-lust and
opted to explore new technologies: <strong>ZFS</strong> and <strong>VMWare ESXi</strong>.</p>

<!-- more -->

<h2 id="going-virtualized">Going Virtualized</h2>
<p>Virtualization is huge in the enterprise-space these days. After talking with
some friends from work about what kind of virtualization strategies we're using
for our in-house datacenter, I became enticed by the idea of running a "bare metal"
<a href="http://en.wikipedia.org/wiki/Hypervisor">hypervisor</a>: install virtualization
software as the primary OS on the physical hardware and spinning up VM's for
different logical needs.</p>

<p>Over the years, I've accumulated a fair amount of old computers. Back in the day,
those extra computers gave me an opportunity to try-out new OSes/software: playing
with different Ubuntu configurations, tinkering with different *BSD flavors, etc.
But once my spare-time dried up, all that old computer hardware just became <em>clutter</em>
taking-up space and it seemed like such a pain to fire up an old computer just to
tinker with some new configuration.</p>

<p>So, going virtualized held a lot of (obvious) appeal to me: minimize my physical
hardware (less power consumed, less physical space, etc.) while letting me easily
tinker with new configurations.</p>

<h2 id="zfs-powered">ZFS-Powered</h2>
<p>Based on <a href="/blog/2011/03/05/zfs-the-last-word-in-filesystems/">previous research</a>,
I knew that I really wanted to move to some kind of <strong>ZFS-backed</strong> storage solution,
to protect/maintain the integrity of my ever-increasing digital collection.</p>

<p>After following the "zfs-discuss" mailing list for a few months, given my simple
home-needs a simple mirrored configuration (along with proper backups) seemed like
the <a href="http://constantin.glez.de/blog/2010/01/home-server-raid-greed-and-why-mirroring-still-best">best solution</a>.
If I need more space, I can expand horizontally: add another pair of drives (of
whatever size is appropriate) to expand my pool. It was this easy expansion
which pushed me towards a mirrored configuration rather than a RAID-Z style
configuration. The trouble with RAID-Z is that you can't add new devices to a
vdev after you've initially created it; the only way to "grow" a RAID-Z vdev is
by replacing <strong>all</strong> of the individual drives (<em>one at a time, waiting for each
to resilver</em>) and setting the "autoexpand" property on the pool so that ZFS
will auto-expand the pool based on the new common maximum size of each of the
individual drives. But, that's a whole lot of moving parts (<em>pun intended</em>) and
replacing all the drives in the pool isn't quite my idea of easy expansion.
Mirroring just seems easier, given that I don't need lots of individual drives
for raw performance reasons.</p>

<h2 id="all-in-one-solution">All-in-One Solution</h2>
<p>Somewhere along the line in my research, I stumbled upon <a href="http://www.napp-it.org/napp-it/all-in-one/index_en.html"><strong>napp-it</strong></a>,
which introduced me to this idea of an "all-in-one" fileserver: using VMWare
ESXi as a bare-metal hypervisor, having a Solaris-based VM running on the ESXi
datastore which will control the mass-storage ZFS pool, and then exporting an
NFS share back out to ESXi so that you can store the bulk of the VMs on
ZFS-backed storage. It's a bit complicated at first glance, but it performs
great (thanks to hardware-passthrough) and lets me easily manage the bulk of my
VMs on ZFS-backed storage.</p>

<p>To make use of ESXi's hardware-passthrough support, you need to run server-grade
hardware. For me, that meant going with an Xeon-based CPU with appropriate motherboard
chipset. But that also gave other server-grade wins like using ECC memory and IPMI
(easy remote-control of the console, which is <em>awesome</em>).</p>

<h2 id="shopping-list">Shopping List</h2>
<p>Here is the hardware I ended-up going with:</p>

<ul>
  <li><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16819117225">Intel Xeon X3440 Lynfield 2.53GHz</a></li>
  <li><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16813182211">Supermicro X8SIL-F-O</a></li>
  <li>2x <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16820139077">Kingston 4GB DDR3 ECC Unbuffered</a></li>
  <li><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16816117157">Intel SASUC8I (LSI 1068E) SATA/SAS card</a></li>
  <li><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16817151088">SeaSonic X650 Gold PSU</a></li>
  <li><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16811352004">Fractal Design Define R3 Mid-Tower Case</a></li>
  <li>2x <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16822145475">2TB Hitachi Deskstar 5K3000</a> (primary pool)</li>
  <li>2x <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16822145475">2TB Hitachi Deskstar 5K3000</a> (backup pool)</li>
  <li>2x <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16822145475">2TB Hitachi Deskstar 5K3000</a> (off-site backup pool)</li>
</ul>

<p>The Xeon chipset was needed for some of the hardware passthrough features in
ESXi, e.g. passing through the HBA card directly to the Solaris-based VM so
that ZFS can have direct access to the physical drives.</p>

<p>The 650W power-supply ended-up being way more than I needed. The server uses
less than 100W when idle, though that PSU is still quite efficient even with
such low power draw.</p>

<h2 id="looking-back">Looking Back</h2>
<p>The setup has been awesome so far. Even just getting to play around with
server-grade hardware has been an eye-opening experience. Being able to
remote-control the server, e.g. mounting an ISO remotely over the Java-based
client and installing the OS on the computer all without needing to hook-up a
keyboard or monitor, has been a revelation.  (<em>Goodbye old CRT monitor that I
used to keep around for my server closet!</em>)</p>

<p>I love the flexibility of ESXi. I have an Ubuntu VM for development/testing, a
FreeBSD VM for running Mediatomb (PS3 media-server), etc. It even let me play
around with different Solaris flavors while trying to figure out what OS I
wanted to use for the ZFS back-end. It's just so easy to spin-up new VMs to
test an idea or just to play around.</p>

<p>I started out using Solaris 11 Edition (free), which ran fine for the better
part of a year. I tried upgrading to Solaris 11/11 earlier this year only to
find that Solaris 11 apparently doesn't play nicely with ESXi. From there, I
jumped over to using <a href="http://openindiana.org/">OpenIndiana</a>, the open-source
spin-off from the now-defunct OpenSolaris lineage.</p>

<p>ZFS has been a huge win too. Taking nightly snapshots makes it dead-easy to
look back in time to see how day was several months ago. The snapshots also
make it easy to send the incremental differences to a backup pool. The built-in
CIFS server makes it dead-easy to mount the shares on Windows, and the
filesystem snapshots are easily accessible via the "Previous Versions" tab in
Windows Explorer. I also really love the idea of the "pool". I can create
different filesystems to group/organize my data (e.g. photos vs. music vs.
backups), enable compression on a per-filesystem basis, set quotas per
filesystem, etc.</p>

<p>I really love the "all-in-one" idea: ZFS reliability combined with the
flexibility of VMWare ESXi.</p>

</article>








  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'nynim';
    var disqus_identifier = 'http://nynim.org/blog/2012/06/04/all-in-one-home-file-server-vmware-esxi-openindiana-and-zfs/';
    var disqus_title      = "All-In-One Home File Server: VMware ESXi, OpenIndiana, and ZFS";

    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>






      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
      &copy; 2017 Tony Duckles.
      Powered by <a href="https://jekyllrb.com/">Jekyll</a>
      and <a href="https://github.com/octopress/octopress">Octopress 3</a>.
      Theme based on <a href="https://github.com/johnotander/pixyll">Pixyll</a>.
    </small>
  </div>
</footer>
</body>
</html>
